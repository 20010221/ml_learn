{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 问答题\n",
    "1. 支持向量机的基本思想是什么？\n",
    "\n",
    "2. 什么是支持向量？\n",
    "\n",
    "3. 在使用 SVM 时，缩放输入值为什么很重要？\n",
    "\n",
    "4. SVM 分类器在对实例进行分类时能输出置信度分数吗？概率呢？\n",
    "\n",
    "5. 你如何在 LinearSVC、SVC 和 SGDClassifier 之间进行选择？\n",
    "\n",
    "6. 假设你已经使用 RBF 核训练了一个 SVM 分类器，但它似乎欠拟合训练集。\n",
    "   你应该增大还是减小 γ（gamma）？C 呢？\n",
    "\n",
    "7. ε 不敏感模型是什么意思？\n",
    "\n",
    "8. 使用核技巧有什么意义？"
   ],
   "id": "a0b8b340a137572d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 编程题\n",
    "1. 在葡萄酒数据集上训练SVM分类器，可以使用sklearn.datasets.load_wine()加载它。该数据集包含3个不同种植者生产的178个葡萄酒样本的化学分析：目标是训练一个分类模型，该模型能够根据葡萄酒的化学分析预测种植者。由于SVM分类器是二元分类器，将需要使用“一对全部”对所有三个类进行分类。能达到的精度是多少？\n",
    "\n",
    "   \"一对全部\"可以复习 **8_sklearn做分类.ipynb**里的笔记，里面提到了用二元分类器做多分类问题\n",
    "\n",
    "---\n",
    "\n",
    "2. 提前预习 **10_支持向量机.ipynb** 最新更新的笔记 （把SVM分类用梯度下降实现）； 大概理解笔记后，尝试自己对照笔记 实现用梯度下降实现SVM分类\n",
    "\n",
    "   并把自定义的SVM分类用于 iris data(鸢尾花数据)； 取花瓣长度 和 花瓣宽度特征， 分类 看是不是 分类2的花 （(iris.target == 2)\n",
    "\n",
    "   对比下sklearn自带的SVM分类 和 自定义SVM分类 实现的分类效果\n",
    "\n",
    "---\n",
    "\n",
    "3. 在加州房屋数据集上训练和微调SVM回归器。可以使用原始数据集而不是 在课上使用的调整后的版本，\n",
    "可以使用sklearn.datasets.fetch_california_housing()加载它。目标代表了数十万美元。\n",
    "由于有超过20000个实例，SVM可能会很慢，因此对于超参数调整，应该使用更少的实例（例如2000个）来测试更多的超参数组合。最佳模型的RMSE是多少？\n"
   ],
   "id": "f5a1dfdea31badc1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T03:44:57.794524Z",
     "start_time": "2025-08-12T03:44:52.919578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target"
   ],
   "id": "4210292c3c2ffc48",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T04:01:19.487056Z",
     "start_time": "2025-08-12T04:01:19.480794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_sample, _, y_sample, _ = train_test_split(X, y, train_size=2000, random_state=42)"
   ],
   "id": "4f13b33a71d80029",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T04:01:20.742903Z",
     "start_time": "2025-08-12T04:01:20.739371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipline = make_pipeline(StandardScaler(), SVR())\n",
    "param_candidates = { 'svr__C':[0.5,1,5],\n",
    "                     'svr__kernel':['linear','rbf'],\n",
    "                     'svr__gamma':[0.01,0.1,1]}"
   ],
   "id": "5f470d00aad301a",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T04:08:33.399454Z",
     "start_time": "2025-08-12T04:08:26.476681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_rmse = float('inf')\n",
    "best_params = None\n",
    "for C in param_candidates['svr__C']:\n",
    "    for gamma in param_candidates['svr__gamma']:\n",
    "        for kernel in param_candidates['svr__kernel']:\n",
    "            pipline.set_params(svr__C=C,svr__gamma=gamma,svr__kernel=kernel)\n",
    "            pipline.fit(X_sample, y_sample)\n",
    "            y_pred = pipline.predict(X_sample)\n",
    "            rmse = np.sqrt(mean_squared_error(y_sample, y_pred))\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_params = {'C': C, 'gamma': gamma, 'kernel': kernel}"
   ],
   "id": "b4aad0681b03d7d4",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-12T04:11:53.159821Z",
     "start_time": "2025-08-12T04:10:36.639897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipline.set_params(svr__C=best_params['C'],svr__gamma=best_params['gamma'],svr__kernel=best_params['kernel'])\n",
    "pipline.fit(X,y)\n",
    "fina_y_pred = pipline.predict(X)\n",
    "final_rmse = np.sqrt(mean_squared_error(y, fina_y_pred))\n",
    "print(f\"最佳模型的 RMSE: {final_rmse}\")"
   ],
   "id": "2c20b0d9a9931c31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳模型的 RMSE: 0.4379295381039573\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "874659d965b24435"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
